@misc{schloegel_sok_2024,
	title = {{SoK}: {Prudent} {Evaluation} {Practices} for {Fuzzing}},
	shorttitle = {{SoK}},
	url = {http://arxiv.org/abs/2405.10220},
	doi = {10.1109/SP54263.2024.00137},
	abstract = {Fuzzing has proven to be a highly effective approach to uncover software bugs over the past decade. After AFL popularized the groundbreaking concept of lightweight coverage feedback, the field of fuzzing has seen a vast amount of scientific work proposing new techniques, improving methodological aspects of existing strategies, or porting existing methods to new domains. All such work must demonstrate its merit by showing its applicability to a problem, measuring its performance, and often showing its superiority over existing works in a thorough, empirical evaluation. Yet, fuzzing is highly sensitive to its target, environment, and circumstances, e.g., randomness in the testing process. After all, relying on randomness is one of the core principles of fuzzing, governing many aspects of a fuzzer's behavior. Combined with the often highly difficult to control environment, the reproducibility of experiments is a crucial concern and requires a prudent evaluation setup. To address these threats to validity, several works, most notably Evaluating Fuzz Testing by Klees et al., have outlined how a carefully designed evaluation setup should be implemented, but it remains unknown to what extent their recommendations have been adopted in practice. In this work, we systematically analyze the evaluation of 150 fuzzing papers published at the top venues between 2018 and 2023. We study how existing guidelines are implemented and observe potential shortcomings and pitfalls. We find a surprising disregard of the existing guidelines regarding statistical tests and systematic errors in fuzzing evaluations. For example, when investigating reported bugs, ...},
	urldate = {2024-05-21},
	author = {Schloegel, Moritz and Bars, Nils and Schiller, Nico and Bernhard, Lukas and Scharnowski, Tobias and Crump, Addison and Ebrahim, Arash Ale and Bissantz, Nicolai and Muench, Marius and Holz, Thorsten},
	month = may,
	year = {2024},
	note = {arXiv:2405.10220 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Software Engineering},
}

@inproceedings{gorz_systematic_2023,
	title = {Systematic {Assessment} of {Fuzzers} using {Mutation} {Analysis}},
	isbn = {978-1-939133-37-3},
	url = {https://www.usenix.org/conference/usenixsecurity23/presentation/gorz},
	language = {en},
	urldate = {2024-05-21},
	author = {Görz, Philipp and Mathis, Björn and Hassler, Keno and Güler, Emre and Holz, Thorsten and Zeller, Andreas and Gopinath, Rahul},
	year = {2023},
	pages = {4535--4552},
}

@misc{noauthor_iotfuzzer_nodate,
	title = {{IoTFuzzer}: {Discovering} {Memory} {Corruptions} in {IoT} {Through} {App}-based {Fuzzing} {\textbar} {Welcome}},
	url = {https://homes.luddy.indiana.edu/xw7/publication/iotfuzzer_ndss2018/},
	urldate = {2024-05-21},
}

@article{zhan_toward_2024,
	title = {Toward {Automated} {Field} {Semantics} {Inference} for {Binary} {Protocol} {Reverse} {Engineering}},
	volume = {19},
	issn = {1556-6021},
	url = {https://ieeexplore.ieee.org/document/10291000/keywords#keywords},
	doi = {10.1109/TIFS.2023.3326666},
	abstract = {Network protocol reverse engineering is the basis for many security applications. A common class of protocol reverse engineering methods is based on the analysis of network message traces. After performing message field identification by segmenting messages into multiple fields, a key task is to infer the semantics of the fields. One of the limitations of existing field semantics inference methods is that they usually infer semantics for only a few fields and often require a lot of manual effort. In this paper, we propose an automated field semantics inference method for binary protocol reverse engineering (FSIBP). FSIBP aims to automatically learn semantics inference knowledge from known protocols and use it to infer the semantics of any field of an unknown protocol. To achieve this goal, we design a feature extraction method that can extract features of the field itself and of the field context. We also propose a semantic category aggregation method that abstracts the fine-grained semantics of all fields of known protocols into aggregated semantic categories. Moreover, we make FSIBP infer semantics based on the similarity of fields to semantic categories. The above design enables FSIBP to utilize the semantic knowledge of all fields of known protocols and infer the semantics of any fields of unknown protocols. The whole process of FSIBP does not require any expert knowledge or manual parameter setting. We conduct extensive experiments to demonstrate the effectiveness of FSIBP. Moreover, we find a utility for FSIBP besides field semantics inference, its output can help to detect the mis-segmented fields generated during the message field identification.},
	urldate = {2024-05-21},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Zhan, Mengqi and Li, Yang and Li, Bo and Zhang, Jinchao and Li, Chuanrong and Wang, Weiping},
	year = {2024},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {binary protocol reverse, Data mining, Feature extraction, field semantics inference, Manuals, Protocol reverse engineering, Protocols, Reverse engineering, Security, Semantics},
	pages = {764--776},
}

@article{tao_bit-oriented_2016,
	title = {Bit-oriented format extraction approach for automatic binary protocol reverse engineering},
	volume = {10},
	copyright = {© 2021 The Institution of Engineering and Technology},
	issn = {1751-8636},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/iet-com.2015.0797},
	doi = {10.1049/iet-com.2015.0797},
	abstract = {Protocol message format extraction is a principal process of automatic network protocol reverse engineering when target protocol specifications are not available. However, binary protocol reverse engineering has been a new challenge in recent years for approaches that traditionally have dealt with text-based protocols rather than binary protocols. In this study, the authors propose a novel approach called PRE-Bin that automatically extracts binary-type fields of binary protocols based on fine-grained bits. First, a silhouette coefficient is introduced into the hierarchical clustering to confirm the optimal clustering number of binary frames. Second, a modified multiple sequence alignment algorithm, in which the matching process and back-tracing rules are redesigned, is also proposed to analyse binary field features. Finally, a Bayes decision model is invoked to describe field features and determine bit-oriented field boundaries. The maximum a posteriori criterion is leveraged to complete an optimal protocol format estimation of binary field boundaries. The authors implemented a prototype system of PRE-Bin to infer the specification of binary protocols from actual traffic traces. Experimental results indicate that PRE-Bin effectively extracts binary fields and outperforms the existing algorithms.},
	language = {en},
	number = {6},
	urldate = {2024-05-21},
	journal = {IET Communications},
	author = {Tao, Siyu and Yu, Hongyi and Li, Qing},
	year = {2016},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1049/iet-com.2015.0797},
	keywords = {automatic binary protocol reverse engineering, back-tracing rules, Bayes decision model, Bayes methods, binary field boundaries, binary field features, binary protocols, binary-type fields, bit-oriented field boundaries, bit-oriented format extraction approach, fine grained bits, optimal clustering number, optimal protocol format estimation, protocol message format extraction, reverse engineering, silhouette coefficient, target protocol specifications, text-based protocols},
	pages = {709--716},
}

@article{eceiza_fuzzing_2021,
	title = {Fuzzing the {Internet} of {Things}: {A} {Review} on the {Techniques} and {Challenges} for {Efficient} {Vulnerability} {Discovery} in {Embedded} {Systems}},
	volume = {8},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2327-4662, 2372-2541},
	shorttitle = {Fuzzing the {Internet} of {Things}},
	url = {https://ieeexplore.ieee.org/document/9344712/},
	doi = {10.1109/JIOT.2021.3056179},
	abstract = {With a growing number of embedded devices that create, transform, and send data autonomously at its core, the Internet of Things (IoT) is a reality in different sectors, such as manufacturing, healthcare, or transportation. With this expansion, the IoT is becoming more present in critical environments, where security is paramount. Infamous attacks, such as Mirai, have shown the insecurity of the devices that power the IoT, as well as the potential of such large-scale attacks. Therefore, it is important to secure these embedded systems that form the backbone of the IoT. However, the particular nature of these devices and their resource constraints mean that the most cost-effective manner of securing these devices is to secure them before they are deployed, by minimizing the number of vulnerabilities they ship. To this end, fuzzing has proved itself as a valuable technique for automated vulnerability ﬁnding, where specially crafted inputs are fed to programs in order to trigger vulnerabilities and crash the system. In this survey, we link the world of embedded IoT devices and fuzzing. For this end, we list the particularities of the embedded world as far as security is concerned, we perform a literature review on fuzzing techniques and proposals, studying their applicability to embedded IoT devices and, ﬁnally, we present future research directions by pointing out the gaps identiﬁed in the review.},
	language = {en},
	number = {13},
	urldate = {2024-05-21},
	journal = {IEEE Internet of Things Journal},
	author = {Eceiza, Maialen and Flores, Jose Luis and Iturbe, Mikel},
	month = jul,
	year = {2021},
	pages = {10390--10411},
}

@misc{jiang_survey_2024,
	title = {A {Survey} of {Network} {Protocol} {Fuzzing}: {Model}, {Techniques} and {Directions}},
	shorttitle = {A {Survey} of {Network} {Protocol} {Fuzzing}},
	url = {http://arxiv.org/abs/2402.17394},
	abstract = {As one of the most successful and effective software testing techniques in recent years, fuzz testing has uncovered numerous bugs and vulnerabilities in modern software, including network protocol software. In contrast to other fuzzing targets, network protocol software exhibits its distinct characteristics and challenges, introducing a plethora of research questions that need to be addressed in the design and implementation of network protocol fuzzers. While some research work has evaluated and systematized the knowledge of general fuzzing techniques at a high level, there is a lack of similar analysis and summarization for fuzzing research specific to network protocols. This paper offers a comprehensive exposition of network protocol software’s fuzzing-related features and conducts a systematic review of some representative advancements in network protocol fuzzing since its inception. We summarize state-of-the-art strategies and solutions in various aspects, propose a unified protocol fuzzing process model, and introduce the techniques involved in each stage of the model. At the same time, this paper also summarizes the promising research directions in the landscape of protocol fuzzing to foster exploration within the community for more efficient and intelligent modern network protocol fuzzing techniques.},
	language = {en},
	urldate = {2024-05-27},
	publisher = {arXiv},
	author = {Jiang, Shihao and Zhang, Yu and Li, Junqiang and Yu, Hongfang and Luo, Long and Sun, Gang},
	month = feb,
	year = {2024},
	note = {arXiv:2402.17394 [cs]},
	keywords = {Computer Science - Networking and Internet Architecture},
}

@misc{noauthor_embedded_nodate,
	title = {Embedded fuzzing: a review of challenges, tools, and solutions {\textbar} {Cybersecurity} {\textbar} {Full} {Text}},
	url = {https://cybersecurity.springeropen.com/articles/10.1186/s42400-022-00123-y},
	urldate = {2024-05-27},
}

@article{eisele_embedded_2022,
	title = {Embedded fuzzing: a review of challenges, tools, and solutions},
	volume = {5},
	issn = {2523-3246},
	shorttitle = {Embedded fuzzing},
	url = {https://doi.org/10.1186/s42400-022-00123-y},
	doi = {10.1186/s42400-022-00123-y},
	abstract = {Fuzzing has become one of the best-established methods to uncover software bugs. Meanwhile, the market of embedded systems, which binds the software execution tightly to the very hardware architecture, has grown at a steady pace, and that pace is anticipated to become yet more sustained in the near future. Embedded systems also benefit from fuzzing, but the innumerable existing architectures and hardware peripherals complicate the development of general and usable approaches, hence a plethora of tools have recently appeared. Here comes a stringent need for a systematic review in the area of fuzzing approaches for embedded systems, which we term “embedded fuzzing” for brevity. The inclusion criteria chosen in this article are semi-objective in their coverage of the most relevant publication venues as well as of our personal judgement. The review rests on a formal definition we develop to represent the realm of embedded fuzzing. It continues by discussing the approaches that satisfy the inclusion criteria, then defines the relevant elements of comparison and groups the approaches according to how the execution environment is served to the system under test. The resulting review produces a table with 42 entries, which in turn supports discussion suggesting vast room for future research due to the limitations noted.},
	number = {1},
	urldate = {2024-05-27},
	journal = {Cybersecurity},
	author = {Eisele, Max and Maugeri, Marcello and Shriwas, Rachna and Huth, Christopher and Bella, Giampaolo},
	month = sep,
	year = {2022},
	keywords = {Dynamic analysis, Embedded security, Embedded systems, Software security, Vulnerability mining},
	pages = {18},
}

@book{herbert_linux_2004,
	address = {Hingham, Mass},
	edition = {1st ed},
	series = {Charles {River} {Media} programming series},
	title = {The {Linux} {TCP}/{IP} stack: networking for embedded systems},
	isbn = {978-1-58450-284-5},
	shorttitle = {The {Linux} {TCP}/{IP} stack},
	language = {en},
	publisher = {Charles River Media},
	author = {Herbert, Thomas F.},
	year = {2004},
	keywords = {Embedded Internet devices, Linux, Operating systems (Computers), TCP/IP (Computer network protocol)},
}

@incollection{thuraisingham_pulsar_2015,
	address = {Cham},
	title = {Pulsar: {Stateful} {Black}-{Box} {Fuzzing} of {Proprietary} {Network} {Protocols}},
	volume = {164},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-319-28864-2 978-3-319-28865-9},
	shorttitle = {Pulsar},
	url = {http://link.springer.com/10.1007/978-3-319-28865-9_18},
	abstract = {The security of network services and their protocols critically depends on minimizing their attack surface. A single ﬂaw in an implementation can sufﬁce to compromise a service and expose sensitive data to an attacker. The discovery of vulnerabilities in protocol implementations, however, is a challenging task: While for standard protocols this process can be conducted with regular techniques for auditing, the situation becomes difﬁcult for proprietary protocols if neither the program code nor the speciﬁcation of the protocol are easily accessible. As a result, vulnerabilities in closed-source implementations can often remain undiscovered for a longer period of time. In this paper, we present PULSAR, a method for stateful black-box fuzzing of proprietary network protocols. Our method combines concepts from fuzz testing with techniques for automatic protocol reverse engineering and simulation. It proceeds by observing the trafﬁc of a proprietary protocol and inferring a generative model for message formats and protocol states that can not only analyze but also simulate communication. During fuzzing this simulation can effectively explore the protocol state space and thereby enables uncovering vulnerabilities deep inside the protocol implementation. We demonstrate the efﬁcacy of PULSAR in two case studies, where it identiﬁes known as well as unknown vulnerabilities.},
	language = {en},
	urldate = {2024-06-26},
	booktitle = {Security and {Privacy} in {Communication} {Networks}},
	publisher = {Springer International Publishing},
	author = {Gascon, Hugo and Wressnegger, Christian and Yamaguchi, Fabian and Arp, Daniel and Rieck, Konrad},
	editor = {Thuraisingham, Bhavani and Wang, XiaoFeng and Yegneswaran, Vinod},
	year = {2015},
	doi = {10.1007/978-3-319-28865-9_18},
	note = {Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
	pages = {330--347},
}

@inproceedings{pham_aflnet_2020,
	address = {Porto, Portugal},
	title = {{AFLNET}: {A} {Greybox} {Fuzzer} for {Network} {Protocols}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-72815-778-8},
	shorttitle = {{AFLNET}},
	url = {https://ieeexplore.ieee.org/document/9159093/},
	doi = {10.1109/ICST46399.2020.00062},
	abstract = {Server fuzzing is difﬁcult. Unlike simple commandline tools, servers feature a massive state space that can be traversed effectively only with well-deﬁned sequences of input messages. Valid sequences are speciﬁed in a protocol. In this paper, we present AFLNET, the ﬁrst greybox fuzzer for protocol implementations. Unlike existing protocol fuzzers, AFLNET takes a mutational approach and uses state-feedback to guide the fuzzing process. AFLNET is seeded with a corpus of recorded message exchanges between the server and an actual client. No protocol speciﬁcation or message grammars are required. AFLNET acts as a client and replays variations of the original sequence of messages sent to the server and retains those variations that were effective at increasing the coverage of the code or state space. To identify the server states that are exercised by a message sequence, AFLNET uses the server’s response codes. From this feedback, AFLNET identiﬁes progressive regions in the state space, and systematically steers towards such regions. The case studies with AFLNET on two popular protocol implementations demonstrate a substantial performance boost over the state-ofthe-art. AFLNET discovered two new CVEs which are classiﬁed as critical (CVSS score CRITICAL 9.8).},
	language = {en},
	urldate = {2024-08-23},
	booktitle = {2020 {IEEE} 13th {International} {Conference} on {Software} {Testing}, {Validation} and {Verification} ({ICST})},
	publisher = {IEEE},
	author = {Pham, Van-Thuan and Bohme, Marcel and Roychoudhury, Abhik},
	month = oct,
	year = {2020},
	pages = {460--465},
}

@misc{feng_snipuzz_2021,
	title = {Snipuzz: {Black}-box {Fuzzing} of {IoT} {Firmware} via {Message} {Snippet} {Inference}},
	shorttitle = {Snipuzz},
	url = {http://arxiv.org/abs/2105.05445},
	doi = {10.48550/arXiv.2105.05445},
	abstract = {The proliferation of Internet of Things (IoT) devices has made people's lives more convenient, but it has also raised many security concerns. Due to the difficulty of obtaining and emulating IoT firmware, the black-box fuzzing of IoT devices has become a viable option. However, existing black-box fuzzers cannot form effective mutation optimization mechanisms to guide their testing processes, mainly due to the lack of feedback. It is difficult or even impossible to apply existing grammar-based fuzzing strategies. Therefore, an efficient fuzzing approach with syntax inference is required in the IoT fuzzing domain. To address these critical problems, we propose a novel automatic black-box fuzzing for IoT firmware, termed Snipuzz. Snipuzz runs as a client communicating with the devices and infers message snippets for mutation based on the responses. Each snippet refers to a block of consecutive bytes that reflect the approximate code coverage in fuzzing. This mutation strategy based on message snippets considerably narrows down the search space to change the probing messages. We compared Snipuzz with four state-of-the-art IoT fuzzing approaches, i.e., IoTFuzzer, BooFuzz, Doona, and Nemesys. Snipuzz not only inherits the advantages of app-based fuzzing (e.g., IoTFuzzer, but also utilizes communication responses to perform efficient mutation. Furthermore, Snipuzz is lightweight as its execution does not rely on any prerequisite operations, such as reverse engineering of apps. We also evaluated Snipuzz on 20 popular real-world IoT devices. Our results show that Snipuzz could identify 5 zero-day vulnerabilities, and 3 of them could be exposed only by Snipuzz. All the newly discovered vulnerabilities have been confirmed by their vendors.},
	urldate = {2024-09-09},
	publisher = {arXiv},
	author = {Feng, Xiaotao and Sun, Ruoxi and Zhu, Xiaogang and Xue, Minhui and Wen, Sheng and Liu, Dongxi and Nepal, Surya and Xiang, Yang},
	month = may,
	year = {2021},
	note = {arXiv:2105.05445 [cs]},
	keywords = {Computer Science - Cryptography and Security, D.2.5, J.7},
}

@inproceedings{dolan-gavitt_lava_2016,
	title = {{LAVA}: {Large}-{Scale} {Automated} {Vulnerability} {Addition}},
	shorttitle = {{LAVA}},
	url = {https://ieeexplore.ieee.org/document/7546498},
	doi = {10.1109/SP.2016.15},
	abstract = {Work on automating vulnerability discovery has long been hampered by a shortage of ground-truth corpora with which to evaluate tools and techniques. This lack of ground truth prevents authors and users of tools alike from being able to measure such fundamental quantities as miss and false alarm rates. In this paper, we present LAVA, a novel dynamic taint analysis-based technique for producing ground-truth corpora by quickly and automatically injecting large numbers of realistic bugs into program source code. Every LAVA bug is accompanied by an input that triggers it whereas normal inputs are extremely unlikely to do so. These vulnerabilities are synthetic but, we argue, still realistic, in the sense that they are embedded deep within programs and are triggered by real inputs. Using LAVA, we have injected thousands of bugs into eight real-world programs, including bash, tshark, and the GNU coreutils. In a preliminary evaluation, we found that a prominent fuzzer and a symbolic execution-based bug finder were able to locate some but not all LAVA-injected bugs, and that interesting patterns and pathologies were already apparent in their performance. Our work forms the basis of an approach for generating large ground-truth vulnerability corpora on demand, enabling rigorous tool evaluation and providing a high-quality target for tool developers.},
	urldate = {2024-09-08},
	booktitle = {2016 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Dolan-Gavitt, Brendan and Hulin, Patrick and Kirda, Engin and Leek, Tim and Mambretti, Andrea and Robertson, Wil and Ulrich, Frederick and Whelan, Ryan},
	month = may,
	year = {2016},
	note = {ISSN: 2375-1207},
	keywords = {Security, Computer bugs, Geophysical measurement techniques, Ground penetrating radar, Length measurement, Pathology, Privacy},
	pages = {110--121},
}

@inproceedings{chen_towards_2022,
	title = {Towards {Effective} {Performance} {Fuzzing}},
	url = {https://ieeexplore.ieee.org/document/9985101},
	doi = {10.1109/ISSREW55968.2022.00055},
	abstract = {Fuzzing is an automated testing technique that utilizes injection of random inputs in a target program to help uncover vulnerabilities. Performance fuzzing extends the classic fuzzing approach and generates inputs that trigger poor performance. During our evaluation of performance fuzzing tools, we have identified certain conventionally used assumptions that do not always hold true. Our research (re)evaluates PERFFUZZ [1] in order to identify the limitations of current techniques, and guide the direction of future work for improvements to performance fuzzing. Our experimental results highlight two specific limitations. Firstly, we identify the assumption that the length of execution paths correlate to program performance is not always the case, and thus cannot reflect the quality of test cases generated by performance fuzzing. Secondly, the default testing parameters by the fuzzing process (timeouts and size limits) overly confine the input search space. Based on these observations, we suggest further investigation on performance fuzzing guidance, as well as controlled fuzzing and testing parameters.},
	urldate = {2024-09-08},
	booktitle = {2022 {IEEE} {International} {Symposium} on {Software} {Reliability} {Engineering} {Workshops} ({ISSREW})},
	author = {Chen, Yiqun and Bradbury, Matthew and Suri, Neeraj},
	month = oct,
	year = {2022},
	keywords = {Aerospace electronics, Conferences, Fuzzing, input selection, metrics, performance fuzzing, Software reliability, Testing},
	pages = {128--129},
}

@article{garshasbi_cnnpre_2023,
	title = {{CNNPRE}: {A} {CNN}-{Based} {Protocol} {Reverse} {Engineering} {Method}},
	volume = {11},
	issn = {2169-3536},
	shorttitle = {{CNNPRE}},
	url = {https://ieeexplore.ieee.org/document/10287339/?arnumber=10287339},
	doi = {10.1109/ACCESS.2023.3325391},
	abstract = {Given the growth in computer networks and Internet usage, the traditional network environment has evolved into a more intricate system. Many applications utilize unknown communication protocols, for which the specification documentation is not available. The use of undocumented network protocols raises various security and management concerns. Protocol reverse engineering based on network traffic aims to infer the behavior and format of unknown network protocols. Clustering same-type messages or packets is a crucial initial step in correctly performing reverse engineering of protocol syntax or behavior. Therefore, this paper proposes a new method called CNNPRE, utilizing deep learning techniques to identify and group traffic message types. Our method employs network traffic and traffic features as input. Specifically, we use convolutional neural networks and deep transfer learning for feature extraction and message type identification and to tackle the challenge of unlabeled training data in the real world scenarios of protocol reverse engineering. The experimental results demonstrate that our proposed method works well and outperforms other methods for different protocols and achieves an average Homogeneity score of more than 0.87 on all datasets. This means that the method can identify message types according to the changing characteristics of messages and traffic features without the need for human expert intervention.},
	urldate = {2024-09-08},
	journal = {IEEE Access},
	author = {Garshasbi, Javad and Teimouri, Mehdi},
	year = {2023},
	note = {Conference Name: IEEE Access},
	keywords = {Feature extraction, Protocols, Reverse engineering, Clustering algorithms, Convolutional neural networks, deep learning, deep transfer learning, message type identification, network protocols, protocol reverse engineering, Telecommunication traffic, Transfer learning},
	pages = {116255--116268},
}

@article{kim_evaluating_2024,
	title = {Evaluating {Directed} {Fuzzers}: {Are} {We} {Heading} in the {Right} {Direction}?},
	volume = {1},
	issn = {2994-970X},
	shorttitle = {Evaluating {Directed} {Fuzzers}},
	url = {https://dl.acm.org/doi/10.1145/3643741},
	doi = {10.1145/3643741},
	abstract = {TAE EUN KIM, KAIST, Korea JAESEUNG CHOI∗, Sogang University, Korea SEONGJAE IM, KAIST, Korea KIHONG HEO, KAIST, Korea SANG KIL CHA, KAIST, Korea Directed fuzzing recently has gained signiﬁcant attention due to its ability to reconstruct proof-of-concept (PoC) test cases for target code such as buggy lines or functions. Surprisingly, however, there has been no in-depth study on the way to properly evaluate directed fuzzers despite much progress in the ﬁeld. In this paper, we present the ﬁrst systematic study on the evaluation of directed fuzzers. In particular, we analyze common pitfalls in evaluating directed fuzzers with extensive experiments on ﬁve state-of-the-art tools, which amount to 30 CPU-years of computational eﬀort, in order to conﬁrm that diﬀerent choices made at each step of the evaluation process can signiﬁcantly impact the results. For example, we ﬁnd that a small change in the crash triage logic can substantially aﬀect the measured performance of a directed fuzzer, while the majority of the papers we studied do not fully disclose their crash triage scripts. We argue that disclosing the whole evaluation process is essential for reproducing research and facilitating future work in the ﬁeld of directed fuzzing. In addition, our study reveals that several common evaluation practices in the current directed fuzzing literature can mislead the overall assessments. Thus, we identify such mistakes in previous papers and propose guidelines for evaluating directed fuzzers. CCS Concepts: • Software and its engineering → Software testing and debugging; • Security and privacy → Software and application security.},
	language = {en},
	number = {FSE},
	urldate = {2024-09-07},
	journal = {Proceedings of the ACM on Software Engineering},
	author = {Kim, Tae Eun and Choi, Jaeseung and Im, Seongjae and Heo, Kihong and Cha, Sang Kil},
	month = jul,
	year = {2024},
	pages = {316--337},
}

@article{eceiza_improving_2023,
	title = {Improving fuzzing assessment methods through the analysis of metrics and experimental conditions},
	volume = {124},
	issn = {0167-4048},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404822003388},
	doi = {10.1016/j.cose.2022.102946},
	abstract = {Fuzzing is nowadays one of the most widely used bug hunting techniques. By automatically generating malformed inputs, fuzzing aims to trigger unwanted behavior on its target. While fuzzing research has matured considerably in the last years, the evaluation and comparison of different fuzzing proposals remain challenging, as no standard set of metrics, data, or experimental conditions exist to allow such observation. This paper aims to fill that gap by proposing a standard set of features to allow such comparison. For that end, it first reviews the existing evaluation methods in the literature and discusses all existing metrics by evaluating seven fuzzers under identical experimental conditions. After examining the obtained results, it recommends a set of practices –particularly on the metrics to be used–, to allow proper comparison between different fuzzing proposals.},
	urldate = {2024-09-07},
	journal = {Computers \& Security},
	author = {Eceiza, Maialen and Flores, Jose Luis and Iturbe, Mikel},
	month = jan,
	year = {2023},
	keywords = {Security, Fuzzing, Evaluation methodology, Metrics, Software testing},
	pages = {102946},
}

@misc{noauthor_ai_nodate,
	title = {{AI} {Based} {Framework} for {Automatic} {Test} {Data} {Generation}},
}

@inproceedings{bohme_directed_2017,
	address = {Dallas Texas USA},
	title = {Directed {Greybox} {Fuzzing}},
	isbn = {978-1-4503-4946-8},
	url = {https://dl.acm.org/doi/10.1145/3133956.3134020},
	doi = {10.1145/3133956.3134020},
	abstract = {Existing Greybox Fuzzers (GF) cannot be effectively directed, for instance, towards problematic changes or patches, towards critical system calls or dangerous locations, or towards functions in the stacktrace of a reported vulnerability that we wish to reproduce.},
	language = {en},
	urldate = {2024-08-30},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Böhme, Marcel and Pham, Van-Thuan and Nguyen, Manh-Dung and Roychoudhury, Abhik},
	month = oct,
	year = {2017},
	pages = {2329--2344},
}

@inproceedings{bekrar_finding_2011,
	title = {Finding {Software} {Vulnerabilities} by {Smart} {Fuzzing}},
	url = {https://ieeexplore.ieee.org/document/5770635},
	doi = {10.1109/ICST.2011.48},
	abstract = {Nowadays, one of the most effective ways to identify software vulnerabilities by testing is the use of fuzzing, whereby the robustness of software is tested against invalid inputs that play on implementation limits or data boundaries. A high number of random combinations of such inputs are sent to the system through its interfaces. Although fuzzing is a fast technique which detects real errors, its efficiency should be improved. Indeed, the main drawbacks of fuzz testing are its poor coverage which involves missing many errors, and the quality of tests. Enhancing fuzzing with advanced approaches such as: data tainting and coverage analysis would improve its efficiency and make it smarter. This paper will present an idea on how these techniques when combined give better error detection by iteratively guiding executions and generating the most pertinent test cases able to trigger potential vulnerabilities and maximize the coverage of testing.},
	urldate = {2024-08-30},
	booktitle = {Verification and {Validation} 2011 {Fourth} {IEEE} {International} {Conference} on {Software} {Testing}},
	author = {Bekrar, Sofia and Bekrar, Chaouki and Groz, Roland and Mounier, Laurent},
	month = mar,
	year = {2011},
	note = {ISSN: 2159-4848},
	keywords = {Security, Testing, Algorithm design and analysis, Assembly, fuzzing, Instruments, Monitoring, Software, software vulnerabilities, testing},
	pages = {427--430},
}

@inproceedings{chen_learning-guided_2019,
	title = {Learning-{Guided} {Network} {Fuzzing} for {Testing} {Cyber}-{Physical} {System} {Defences}},
	url = {http://arxiv.org/abs/1909.05410},
	doi = {10.1109/ASE.2019.00093},
	abstract = {The threat of attack faced by cyber-physical systems (CPSs), especially when they play a critical role in automating public infrastructure, has motivated research into a wide variety of attack defence mechanisms. Assessing their effectiveness is challenging, however, as realistic sets of attacks to test them against are not always available. In this paper, we propose smart fuzzing, an automated, machine learning guided technique for systematically ﬁnding ‘test suites’ of CPS network attacks, without requiring any knowledge of the system’s control programs or physical processes. Our approach uses predictive machine learning models and metaheuristic search algorithms to guide the fuzzing of actuators so as to drive the CPS into different unsafe physical states. We demonstrate the efﬁcacy of smart fuzzing by implementing it for two real-world CPS testbeds—a water puriﬁcation plant and a water distribution system—ﬁnding attacks that drive them into 27 different unsafe states involving water ﬂow, pressure, and tank levels, including six that were not covered by an established attack benchmark. Finally, we use our approach to test the effectiveness of an invariant-based defence system for the water treatment plant, ﬁnding two attacks that were not detected by its physical invariant checks, highlighting a potential weakness that could be exploited in certain conditions.},
	language = {en},
	urldate = {2024-08-30},
	booktitle = {2019 34th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE})},
	author = {Chen, Yuqi and Poskitt, Christopher M. and Sun, Jun and Adepu, Sridhar and Zhang, Fan},
	month = nov,
	year = {2019},
	note = {arXiv:1909.05410 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	pages = {962--973},
}

@article{li_fuzzing_2018,
	title = {Fuzzing: a survey},
	volume = {1},
	issn = {2523-3246},
	shorttitle = {Fuzzing},
	url = {https://doi.org/10.1186/s42400-018-0002-y},
	doi = {10.1186/s42400-018-0002-y},
	abstract = {Security vulnerability is one of the root causes of cyber-security threats. To discover vulnerabilities and fix them in advance, researchers have proposed several techniques, among which fuzzing is the most widely used one. In recent years, fuzzing solutions, like AFL, have made great improvements in vulnerability discovery. This paper presents a summary of the recent advances, analyzes how they improve the fuzzing process, and sheds light on future work in fuzzing. Firstly, we discuss the reason why fuzzing is popular, by comparing different commonly used vulnerability discovery techniques. Then we present an overview of fuzzing solutions, and discuss in detail one of the most popular type of fuzzing, i.e., coverage-based fuzzing. Then we present other techniques that could make fuzzing process smarter and more efficient. Finally, we show some applications of fuzzing, and discuss new trends of fuzzing and potential future directions.},
	number = {1},
	urldate = {2024-08-30},
	journal = {Cybersecurity},
	author = {Li, Jun and Zhao, Bodong and Zhang, Chao},
	month = jun,
	year = {2018},
	keywords = {Software security, Fuzzing, Coverage-based fuzzing, Vulnerability discovery},
	pages = {6},
}

@misc{noauthor_cysecbooksfuzzing_nodate,
	title = {{CySecBooks}/{Fuzzing} {Brute} {Force} {Vulnerability} {Discovery}.pdf at master · mangonugen/{CySecBooks}},
	url = {https://github.com/mangonugen/CySecBooks/blob/master/Fuzzing%20Brute%20Force%20Vulnerability%20Discovery.pdf},
	abstract = {Libros de Cyber Security. Contribute to mangonugen/CySecBooks development by creating an account on GitHub.},
	language = {en},
	urldate = {2024-08-30},
	journal = {GitHub},
}

@article{liang_fuzzing_2018,
	title = {Fuzzing: {State} of the {Art}},
	volume = {67},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0018-9529, 1558-1721},
	shorttitle = {Fuzzing},
	url = {https://ieeexplore.ieee.org/document/8371326/},
	doi = {10.1109/TR.2018.2834476},
	abstract = {As one of the most popular software testing techniques, fuzzing can ﬁnd a variety of weaknesses in a program, such as software bugs and vulnerabilities, by generating numerous test inputs. Due to its effectiveness, fuzzing is regarded as a valuable bug hunting method. In this paper, we present an overview of fuzzing that concentrates on its general process, as well as classiﬁcations, followed by detailed discussion of the key obstacles and some stateof-the-art technologies which aim to overcome or mitigate these obstacles. We further investigate and classify several widely used fuzzing tools. Our primary goal is to equip the stakeholder with a better understanding of fuzzing and the potential solutions for improving fuzzing methods in the spectrum of software testing and security. To inspire future research, we also predict some future directions with regard to fuzzing.},
	language = {en},
	number = {3},
	urldate = {2024-08-30},
	journal = {IEEE Transactions on Reliability},
	author = {Liang, Hongliang and Pei, Xiaoxiao and Jia, Xiaodong and Shen, Wuwei and Zhang, Jian},
	month = sep,
	year = {2018},
	pages = {1199--1218},
}
